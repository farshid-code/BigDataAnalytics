{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext(\"local\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You need to load twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data\\\\tweets.csv\",header=True,inferSchema=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the special chars. Only lettere will reamin.\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(F.col(\"text\"), \"[^a-zA-Z ]\", \"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|              text_c|\n",
      "+--------------------+--------------------+\n",
      "|This article also...|This article also...|\n",
      "|Are long covid su...|Are long covid su...|\n",
      "|Are long covid su...|Are long covid su...|\n",
      "|A combination of ...|A combination of ...|\n",
      "|Utter rubbish - m...|Utter rubbish  m ...|\n",
      "|When long covid f...|When long covid f...|\n",
      "|Pretty sure the p...|Pretty sure the p...|\n",
      "|Ive had this ling...|Ive had this ling...|\n",
      "|Less risk of deat...|Less risk of deat...|\n",
      "|Not sure why you ...|Not sure why you ...|\n",
      "|\"Get vaxxed!!!The...|Get vaxxedThe eff...|\n",
      "|Cognitive Rehab: ...|Cognitive Rehab O...|\n",
      "|\"They call being ...|They call being f...|\n",
      "|Incredibly unlike...|Incredibly unlike...|\n",
      "|Have you heard of...|Have you heard of...|\n",
      "|\"Between -30% of ...|Between  of COVID...|\n",
      "|And almost no sid...|And almost no sid...|\n",
      "|Are you seriously...|Are you seriously...|\n",
      "|You cant know the...|You cant know the...|\n",
      "|They only look at...|They only look at...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessin pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "# countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features\", vocabSize=500)\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features\", vocabSize=500,minDF=10, maxDF=20000)\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, countVectorizer])\n",
    "data_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amp', 'symptoms', 'dont', 'children', 'kids', 'many', 'know', 'like', 'still', 'im', 'also', 'risk', 'one', 'vaccine', 'even', 'health', 'months', 'vaccinated', 'getting', 'effects', 'cases', 'longcovid', 'think', 'infection', 'death', 'got', 'study', 'need', 'much', 'suffering', 'us', 'deaths', 'virus', 'thats', 'patients', 'well', 'may', 'year', 'time', 'new', 'really', 'work', 'want', 'vaccines', 'term', 'going', 'doesnt', 'ive', 'damage', 'good', 'die', 'help', 'cant', 'see', 'died', 'life', 'care', 'take', 'better', 'sick', 'data', 'illness', 'youre', 'last', 'less', 'uk', 'go', 'back', 'issues', 'isnt', 'yes', 'say', 'likely', 'disease', 'thing', 'years', 'infected', 'hope', 'mild', 'research', 'suffer', 'brain', 'ill', 'real', 'way', 'never', 'day', 'since', 'fatigue', 'hospital', 'vaccination', 'lot', 'theres', 'weeks', 'immunity', 'yet', 'school', 'first', 'right', 'dying']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = data_model.stages[2].vocabulary\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|              text_c|               words|            filtered|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|This article also...|This article also...|[this, article, a...|[article, also, s...|(500,[10,16,19,40...|\n",
      "|Are long covid su...|Are long covid su...|[are, long, covid...|[long, covid, suf...|(500,[2,14,15,50,...|\n",
      "|Are long covid su...|Are long covid su...|[are, long, covid...|[long, covid, suf...|(500,[2,14,15,50,...|\n",
      "|A combination of ...|A combination of ...|[a, combination, ...|[combination, sti...|(500,[0,8,14,82,2...|\n",
      "|Utter rubbish - m...|Utter rubbish  m ...|[utter, rubbish, ...|[utter, rubbish, ...|(500,[10,20,24,31...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = data_model.transform(df)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(k=5, maxIter=10)\n",
    "model = lda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(500, 5, [118.0321, 1058.7327, 296.776, 98.2211, 95.1265, 542.7731, 515.5355, 340.0526, ..., 17.7943, 11.5801, 13.9043, 102.1744, 19.846, 41.5321, 50.4078, 84.4006], 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------+------------------------------------------------------------------+\n",
      "|topic|termIndices|termWeights                                                       |\n",
      "+-----+-----------+------------------------------------------------------------------+\n",
      "|0    |[12, 9, 21]|[0.032417131327915294, 0.024645812111262447, 0.018224085444075482]|\n",
      "|1    |[1, 3, 10] |[0.03682495745380505, 0.019946832286835466, 0.01935900148826528]  |\n",
      "|2    |[4, 3, 6]  |[0.03878542469288138, 0.029372596385178747, 0.019430446212653472] |\n",
      "|3    |[7, 2, 9]  |[0.022667632485560987, 0.01870948448563872, 0.016522576367774842] |\n",
      "|4    |[0, 5, 31] |[0.05627081078650233, 0.034481756970852415, 0.017397646382846868] |\n",
      "+-----+-----------+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'im', 'longcovid', 'infection', 'symptoms', 'death', 'fatigue', 'bad', 'year', 'syndrome']\n",
      "['symptoms', 'children', 'also', 'study', 'know', 'dont', 'think', 'months', 'vaccine', 'got']\n",
      "['kids', 'children', 'know', 'risk', 'still', 'even', 'damage', 'dont', 'effects', 'thats']\n",
      "['like', 'dont', 'im', 'still', 'getting', 'want', 'need', 'take', 'ive', 'time']\n",
      "['amp', 'many', 'deaths', 'cases', 'health', 'longcovid', 'us', 'thousands', 'virus', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Print most important topic per category\n",
    "topics = model.describeTopics(10)\n",
    "for r in topics.select(\"termIndices\").collect():\n",
    "    rez = []\n",
    "    for l in r:\n",
    "        for i in l:\n",
    "            rez.append(vocabulary[i])\n",
    "    print(rez[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = [\"peoples\",\"children\",\"vaccinated\",\"fatal\",\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              text_c|   topicDistribution|\n",
      "+--------------------+--------------------+\n",
      "|This article also...|[0.01948154677057...|\n",
      "|Are long covid su...|[0.47114690695234...|\n",
      "|Are long covid su...|[0.47114690695234...|\n",
      "|A combination of ...|[0.03206051277963...|\n",
      "|Utter rubbish  m ...|[0.28458044019144...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the result\n",
    "transformed = model.transform(dataset)\n",
    "transformed.select(\"text_c\",\"topicDistribution\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf\n",
    "def vect_argmax(row):\n",
    "    row_arr = row.toArray()\n",
    "    max_pos = np.argmax(row_arr)\n",
    "    return(int(max_pos))\n",
    "transformed1 = transformed.withColumn(\"argmax\",vect_argmax(F.col('topicDistribution')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|text_c                                                                                                                                                                                                                                           |argmax|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|This article also states they consider long Covid up to months there really isnt research of long term effects as its been around                                                                                                                |1     |\n",
      "|Are long covid sufferers now to be classed as had pre existing health conditions if they die due to a reinfection Will they even be counted though given reinfections dont appear on official stats always                                       |4     |\n",
      "|Are long covid sufferers now to be classed as had pre existing health conditions if they die due to a reinfection Will they even be counted though given reinfections dont appear on official stats always                                       |4     |\n",
      "|A combination of still being seriously ill with long covid amp hating parties would have stopped me attending Xmas parties even before this but eeeeeesh                                                                                         |3     |\n",
      "|Utter rubbish  m cases and k deaths   mortality rate Thats any death within  days of having covid also so figured highly inflatedThere arent any stats from NHS or ONS on long covid  just made that  stat up Scaremongering or just naive Howard|4     |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed1.select(\"text_c\",\"argmax\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for preprocessing the tweets. Not in Spark.\n",
    "# import pandas as pd\n",
    "\n",
    "# dataset = pd.read_csv(\"data\\\\en_tweets_with_phenotype_counts_new.csv\")\n",
    "\n",
    "# import preprocessor as p\n",
    "# tw = []\n",
    "# for s in df[\"content\"].head(200000):\n",
    "#     tw.append(p.clean(s))\n",
    "# dft = pd.DataFrame(columns=[\"text\"])\n",
    "# dft[\"text\"] = tw\n",
    "# dft.to_csv(\"data\\\\tweets.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7a06dfce2b0bd21e3eb7d00699f7eaeb362c7070a3f1ab86e396ea9b4275c1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
