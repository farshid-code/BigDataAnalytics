{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[ 0.   2.5  5.   7.5 10. ]\n"
     ]
    }
   ],
   "source": [
    "# Let us create some random data\n",
    "# We create a very simple data set with 5 data items in it. \n",
    "size= 5\n",
    "\n",
    "# mu, sigma = 100, 5000 # mean and standard deviation\n",
    "# error=np.random.normal(mu, sigma, size)\n",
    "\n",
    "x1 = np.arange(0, size)\n",
    "# x2 = np.arange(1, size)\n",
    "\n",
    "# y = 2.5*x1 + error\n",
    "y=2.5 * x1\n",
    "\n",
    "# y = 2*x1 + 10* x2\n",
    "\n",
    "plt.plot(x1, y, 'o', markersize=2)\n",
    "plt.show()\n",
    "\n",
    "print(x1)\n",
    "# print(x2)\n",
    "# print(error)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0. ]\n",
      " [ 2.5  1. ]\n",
      " [ 5.   2. ]\n",
      " [ 7.5  3. ]\n",
      " [10.   4. ]]\n",
      "+-----+--------+\n",
      "|label|features|\n",
      "+-----+--------+\n",
      "|0.0  |[0.0]   |\n",
      "|2.5  |[1.0]   |\n",
      "|5.0  |[2.0]   |\n",
      "|7.5  |[3.0]   |\n",
      "|10.0 |[4.0]   |\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "[(0.0, array([0.])), (2.5, array([1.])), (5.0, array([2.])), (7.5, array([3.])), (10.0, array([4.]))]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n",
    "df = np.stack([y, x1], axis=1)\n",
    "print(df)\n",
    "\n",
    "dff = map(lambda x: (float(x[0]), Vectors.dense(x[1:])), df)\n",
    "mydf = spark.createDataFrame(dff, schema=[\"label\", \"features\"])\n",
    "\n",
    "print(mydf.show( truncate=False))\n",
    "\n",
    "\n",
    "# Now, we create an RDD from this data. \n",
    "# X is a numpy array \n",
    "# y is a simple value lable\n",
    "myRDD=mydf.rdd.map(tuple).map(lambda x: (float(x[0]), np.array(x[1]) ))\n",
    "\n",
    "print(myRDD.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sklearn is not installed \n",
    "# !pip3 install -q sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[ 0.   2.5  5.   7.5 10. ]\n",
      "[2.5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# X = np.stack([x1, x2], axis=1)\n",
    "X = np.stack([x1], axis=1)\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "# reg.score(X, y)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5]\n"
     ]
    }
   ],
   "source": [
    "# print(np.shape(X.T))\n",
    "# print(np.shape(X))\n",
    "\n",
    "# Let use solve this also with the exact linear algebra solution. \n",
    "beta_hat = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 m= 0  Cost= 187.5\n",
      "1 m= 0.15  Cost= 165.675\n",
      "2 m= 0.29100000000000004  Cost= 146.39043\n",
      "3 m= 0.4235400000000001  Cost= 129.350583948\n",
      "4 m= 0.5481276000000002  Cost= 114.29417597645278\n",
      "5 m= 0.6652399440000002  Cost= 100.99033389279367\n",
      "6 m= 0.7753255473600003  Cost= 89.23505902767249\n",
      "7 m= 0.8788060145184002  Cost= 78.84809815685139\n",
      "8 m= 0.9760776536472963  Cost= 69.67017953139388\n",
      "9 m= 1.0675129944284585  Cost= 61.56057063393965\n",
      "10 m= 1.153462214762751  Cost= 54.394920212149074\n",
      "11 m= 1.2342544818769858  Cost= 48.063351499454924\n",
      "12 m= 1.3101992129643667  Cost= 42.46877738491837\n",
      "13 m= 1.3815872601865047  Cost= 37.52541169731388\n",
      "14 m= 1.4486920245753143  Cost= 33.157453775746546\n",
      "15 m= 1.5117705031007955  Cost= 29.29792615624964\n",
      "16 m= 1.5710642729147477  Cost= 25.887647551662187\n",
      "17 m= 1.6268004165398628  Cost= 22.874325376648713\n",
      "18 m= 1.6791923915474711  Cost= 20.211753902806798\n",
      "19 m= 1.728440848054623  Cost= 17.859105748520083\n",
      "20 m= 1.7747343971713456  Cost= 15.78030583939234\n",
      "21 m= 1.818250333341065  Cost= 13.943478239687074\n",
      "22 m= 1.859155313340601  Cost= 12.320457372587502\n",
      "23 m= 1.8976059945401649  Cost= 10.886356134418314\n",
      "24 m= 1.933749634867755  Cost= 9.619184280372027\n",
      "25 m= 1.9677246567756896  Cost= 8.499511230136722\n",
      "26 m= 1.9996611773691482  Cost= 7.51016812294881\n",
      "27 m= 2.029681506726999  Cost= 6.635984553437574\n",
      "28 m= 2.057900616323379  Cost= 5.8635559514174425\n",
      "29 m= 2.0844265793439765  Cost= 5.1810380386724475\n"
     ]
    }
   ],
   "source": [
    "# Now, we do gradient descent here with a very simple numpy array \n",
    "\n",
    "learningRate = 0.01\n",
    "num_iteration = 30 \n",
    "m_current=0\n",
    "\n",
    "n = float(size)\n",
    "# print(\"Sample size\", n)\n",
    "\n",
    "# Let's start with main iterative part of gradient descent algorithm \n",
    "for i in range(num_iteration):\n",
    "    \n",
    "    # Calculate the prediction with current regression coefficients. \n",
    "    y_prediction = m_current * x1 \n",
    "    \n",
    "    \n",
    "    # We compute costs just for monitoring \n",
    "    cost= sum (( y - y_prediction)**2)\n",
    "\n",
    "    # calculate gradients. \n",
    "    m_gradient = (-1.0/n) * sum (x1 * (y - y_prediction) )\n",
    "    \n",
    "    \n",
    "    print(i , \"m=\", m_current, \" Cost=\", cost)\n",
    "        \n",
    "    # update the weights - Regression Coefficients \n",
    "    m_current = m_current - learningRate * m_gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Beta [0.]  Cost [187.5]\n",
      "1 Beta [0.15]  Cost [165.675]\n",
      "2 Beta [0.291]  Cost [146.39043]\n",
      "3 Beta [0.42354]  Cost [129.35058395]\n",
      "4 Beta [0.5481276]  Cost [114.29417598]\n",
      "5 Beta [0.66523994]  Cost [100.99033389]\n",
      "6 Beta [0.77532555]  Cost [89.23505903]\n",
      "7 Beta [0.87880601]  Cost [78.84809816]\n",
      "8 Beta [0.97607765]  Cost [69.67017953]\n",
      "9 Beta [1.06751299]  Cost [61.56057063]\n",
      "10 Beta [1.15346221]  Cost [54.39492021]\n",
      "11 Beta [1.23425448]  Cost [48.0633515]\n",
      "12 Beta [1.31019921]  Cost [42.46877738]\n",
      "13 Beta [1.38158726]  Cost [37.5254117]\n",
      "14 Beta [1.44869202]  Cost [33.15745378]\n",
      "15 Beta [1.5117705]  Cost [29.29792616]\n",
      "16 Beta [1.57106427]  Cost [25.88764755]\n",
      "17 Beta [1.62680042]  Cost [22.87432538]\n",
      "18 Beta [1.67919239]  Cost [20.2117539]\n",
      "19 Beta [1.72844085]  Cost [17.85910575]\n",
      "20 Beta [1.7747344]  Cost [15.78030584]\n",
      "21 Beta [1.81825033]  Cost [13.94347824]\n",
      "22 Beta [1.85915531]  Cost [12.32045737]\n",
      "23 Beta [1.89760599]  Cost [10.88635613]\n",
      "24 Beta [1.93374963]  Cost [9.61918428]\n",
      "25 Beta [1.96772466]  Cost [8.49951123]\n",
      "26 Beta [1.99966118]  Cost [7.51016812]\n",
      "27 Beta [2.02968151]  Cost [6.63598455]\n",
      "28 Beta [2.05790062]  Cost [5.86355595]\n",
      "29 Beta [2.08442658]  Cost [5.18103804]\n"
     ]
    }
   ],
   "source": [
    "# Now we do gradient Decent on our RDD data set. \n",
    "learningRate = 0.01\n",
    "num_iteration = 30 \n",
    "\n",
    "beta = np.zeros(1)\n",
    "# print(beta)\n",
    "myRDD.cache()\n",
    "\n",
    "# Let's start with main iterative part of gradient descent algorithm \n",
    "for i in range(num_iteration):\n",
    "    \n",
    "    gradientCost=myRDD.map(lambda x: (x[1], (x[0] - x[1] * beta) ))\\\n",
    "                           .map(lambda x: (x[0]*x[1], x[1]**2 )).reduce(lambda x, y: (x[0] +y[0], x[1]+y[1] ))\n",
    "    \n",
    "    cost= gradientCost[1]\n",
    "    \n",
    "    gradient=(-1/float(size))* gradientCost[0]\n",
    "    \n",
    "    print(i, \"Beta\", beta, \" Cost\", cost)\n",
    "    beta = beta - learningRate * gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
