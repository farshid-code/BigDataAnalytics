{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext(\"local\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|One of the other ...| positive|\n",
      "|A wonderful littl...| positive|\n",
      "|I thought this wa...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "tFile=\"data\\IMDB Dataset.csv.bz2\"\n",
    "df0 = spark.read.csv(tFile,header=True)\n",
    "df0.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment to numbers positive =1, negative =0\n",
    "df0 = df0.withColumn(\"label\", F.when(F.col(\"sentiment\")==\"positive\",1).otherwise(0)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove html tags from text\n",
    "df0 = df0.withColumn(\"text_c\", F.regexp_replace(F.col(\"text\"), r'<[^>]+>', \"\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample the data for faster model training (use the full dataset in reality)\n",
    "df0 = df0.sample(0.25, seed=200)\n",
    "# Split the data in train and test (80%-20%)\n",
    "df, test = df0.randomSplit(weights=[0.8,0.2], seed=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 4984|\n",
      "|    0| 5070|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 1239|\n",
      "|    0| 1280|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5042769047145415 0.49572309528545855\n"
     ]
    }
   ],
   "source": [
    "# Create a weight of each class\n",
    "from pyspark.sql import functions as F\n",
    "p_weight = df.filter('label == 1').count()/ df.count()\n",
    "n_weight = df.filter('label == 0').count()/ df.count()\n",
    "print(n_weight, p_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+--------------------+-------------------+\n",
      "|                text|sentiment|label|              text_c|             weight|\n",
      "+--------------------+---------+-----+--------------------+-------------------+\n",
      "| Domino  has been...| positive|    1| Domino  has been...| 0.5042769047145415|\n",
      "| It had to be You...| negative|    0| It had to be You...|0.49572309528545855|\n",
      "| Så som i himmele...| positive|    1| Så som i himmele...| 0.5042769047145415|\n",
      "| While sporadical...| negative|    0| While sporadical...|0.49572309528545855|\n",
      "|!!!!! POSSIBLE SP...| negative|    0|!!!!! POSSIBLE SP...|0.49572309528545855|\n",
      "+--------------------+---------+-----+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"weight\", F.when(F.col(\"label\")==1,n_weight).otherwise(p_weight))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\",)\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "# hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"rawFeatures\",numFeatues=5000)\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"rawFeatures\", vocabSize=500)\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"featuresIDF\")\n",
    "pipeline_p = Pipeline(stages=[tokenizer,remover, countVectorizer, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "data_model = pipeline_p.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|sentiment|label|              text_c|             weight|               words|            filtered|         rawFeatures|         featuresIDF|\n",
      "+--------------------+---------+-----+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Domino  has been...| positive|    1| Domino  has been...| 0.5042769047145415|[, domino, , has,...|[, domino, , wide...|(500,[0,3,6,11,12...|(500,[0,3,6,11,12...|\n",
      "| It had to be You...| negative|    0| It had to be You...|0.49572309528545855|[, it, had, to, b...|[, another, sign,...|(500,[0,6,12,19,2...|(500,[0,6,12,19,2...|\n",
      "| Så som i himmele...| positive|    1| Så som i himmele...| 0.5042769047145415|[, så, som, i, hi...|[, så, som, himme...|(500,[1,7,8,11,12...|(500,[1,7,8,11,12...|\n",
      "| While sporadical...| negative|    0| While sporadical...|0.49572309528545855|[, while, sporadi...|[, sporadically, ...|(500,[1,3,45,46,5...|(500,[1,3,45,46,5...|\n",
      "|!!!!! POSSIBLE SP...| negative|    0|!!!!! POSSIBLE SP...|0.49572309528545855|[!!!!!, possible,...|[!!!!!, possible,...|(500,[0,1,3,8,11,...|(500,[0,1,3,8,11,...|\n",
      "+--------------------+---------+-----+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transformed_data = data_model.transform(df)\n",
    "transformed_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|sentiment|label|              text_c|               words|            filtered|         rawFeatures|         featuresIDF|\n",
      "+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|!!! Spoiler alert...| negative|    0|!!! Spoiler alert...|[!!!, spoiler, al...|[!!!, spoiler, al...|(500,[1,2,3,5,7,9...|(500,[1,2,3,5,7,9...|\n",
      "|'Loulou' delights...| positive|    1|'Loulou' delights...|['loulou', deligh...|['loulou', deligh...|(500,[1,2,12,14,2...|(500,[1,2,12,14,2...|\n",
      "|'Presque rien' is...| positive|    1|'Presque rien' is...|['presque, rien',...|['presque, rien',...|(500,[0,1,5,11,17...|(500,[0,1,5,11,17...|\n",
      "|'The Luzhin Defen...| positive|    1|'The Luzhin Defen...|['the, luzhin, de...|['the, luzhin, de...|(500,[1,4,10,16,3...|(500,[1,4,10,16,3...|\n",
      "|'The Merchant of ...| positive|    1|'The Merchant of ...|['the, merchant, ...|['the, merchant, ...|(500,[1,2,3,5,7,1...|(500,[1,2,3,5,7,1...|\n",
      "+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transfomr the test data\n",
    "transformed_test = data_model.transform(test)\n",
    "transformed_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tokenizer_ccf7c0193f78,\n",
       " StopWordsRemover_4d8575b368a4,\n",
       " CountVectorizerModel: uid=CountVectorizer_3f04897c75fb, vocabularySize=500,\n",
       " IDFModel: uid=IDF_8b57b0f40bb4, numDocs=10054, numFeatures=500]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the sages of the pipeline\n",
    "data_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie',\n",
       " 'film',\n",
       " 'one',\n",
       " 'like',\n",
       " 'good',\n",
       " 'even',\n",
       " 'really',\n",
       " 'see',\n",
       " '-',\n",
       " 'get',\n",
       " 'much',\n",
       " 'story',\n",
       " 'also',\n",
       " 'time',\n",
       " 'make',\n",
       " 'first',\n",
       " 'great',\n",
       " 'people',\n",
       " 'bad',\n",
       " 'made']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary of the CountVectroizer\n",
    "data_model.stages[2].vocabulary[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.evaluation import MultilabelMetrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def m_metrics(ml_model,test_data):\n",
    "    predictions = ml_model.transform(test_data).cache()\n",
    "    predictionAndLabels = predictions.select(\"label\",\"prediction\").rdd.map(lambda x: (float(x[0]), float(x[1]))).cache()\n",
    "    \n",
    "    # Print some predictions vs labels\n",
    "    print(predictionAndLabels.take(10))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    # Overall statistics\n",
    "    precision = metrics.precision(1.0)\n",
    "    recall = metrics.recall(1.0)\n",
    "    f1Score = metrics.fMeasure(1.0)\n",
    "    print(f\"Precision = {precision:.3f} Recall = {recall:.3f} F1 Score = {f1Score:.3f}\")\n",
    "\n",
    "    # Statistics by class\n",
    "    labels = [0.0, 1.0]\n",
    "    for label in sorted(labels):\n",
    "        print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "        print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "\n",
    "    # Weighted stats\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "    print(\"Confusion matrix \\n\", metrics.confusionMatrix().toArray().astype(int))\n",
    "\n",
    "def m_metrics_l(ml_model,test_data):\n",
    "    predictions = ml_model.transform(test_data).cache()\n",
    "    predictionAndLabels = predictions.select(\"label\",\"prediction\").rdd.map(lambda x: (float(x[0]), float(x[1]))).cache()\n",
    "    \n",
    "    # Print some predictions vs labels\n",
    "    # print(predictionAndLabels.take(10))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    # Overall statistics\n",
    "    precision = metrics.precision(1.0)\n",
    "    recall = metrics.recall(1.0)\n",
    "    f1Score = metrics.fMeasure(1.0)\n",
    "    print(f\"Precision = {precision:.4f} Recall = {recall:.4f} F1 Score = {f1Score:.4f}\")\n",
    "    print(\"Confusion matrix \\n\", metrics.confusionMatrix().toArray().astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 12.15s.\n",
      "Precision = 0.8289 Recall = 0.7967 F1 Score = 0.8125\n",
      "Confusion matrix \n",
      " [[1018  212]\n",
      " [ 262 1027]]\n",
      "Total time 23.80s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#selector = ChiSqSelector(numTopFeatures=200, featuresCol=idf.getOutputCol(), outputCol=\"features\", labelCol=\"label\")\n",
    "cassifier = LogisticRegression(maxIter=5, featuresCol = \"featuresIDF\", weightCol=\"weight\")\n",
    "#cassifier = LinearSVC(maxIter=10,  weightCol=\"weight\")\n",
    "#cassifier = DecisionTreeClassifier(featuresCol=idf.getOutputCol(), weightCol=\"weight\")\n",
    "start = time.time()\n",
    "#cassifier = GBTClassifier(maxIter=50, featuresCol = \"featuresIDF\", weightCol=\"weight\")\n",
    "pipeline = Pipeline(stages=[cassifier])\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 56.40s.\n",
      "Precision = 0.8144 Recall = 0.7007 F1 Score = 0.7533\n",
      "Confusion matrix \n",
      " [[ 849  230]\n",
      " [ 431 1009]]\n",
      "Total time 64.66s.\n"
     ]
    }
   ],
   "source": [
    "cassifier = GBTClassifier(maxIter=10, featuresCol = \"featuresIDF\", maxDepth=10)\n",
    "pipeline = Pipeline(stages=[cassifier])\n",
    "start = time.time()\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 11.93s.\n",
      "Precision = 0.8313 Recall = 0.7960 F1 Score = 0.8133\n",
      "Confusion matrix \n",
      " [[1016  209]\n",
      " [ 264 1030]]\n",
      "Total time 20.13s.\n"
     ]
    }
   ],
   "source": [
    "cassifier = LinearSVC(maxIter=10, featuresCol = \"featuresIDF\", weightCol=\"weight\")\n",
    "pipeline = Pipeline(stages=[cassifier])\n",
    "start = time.time()\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Model created in 17.87s.\n",
      "Precision = 0.7813 Recall = 0.8020 F1 Score = 0.7915\n",
      "Confusion matrix \n",
      " [[1041  271]\n",
      " [ 239  968]]\n",
      "Total time 27.15s.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "layers = [500, 100, 20, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "cassifier = MultilayerPerceptronClassifier(maxIter=10, layers=layers,featuresCol = \"featuresIDF\", blockSize=128, seed=1234)\n",
    "pipeline = Pipeline(stages=[cassifier])\n",
    "start = time.time()\n",
    "print(f\"Training started.\")\n",
    "model = pipeline.fit(transformed_data)\n",
    "print(f\"Model created in {time.time()-start:.2f}s.\")\n",
    "m_metrics_l(model,transformed_test)\n",
    "print(f\"Total time {time.time()-start:.2f}s.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a438fe5e673439fc02ff5cd8cbdc8c17eb0482df38f5adb73093864426e0f81e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
