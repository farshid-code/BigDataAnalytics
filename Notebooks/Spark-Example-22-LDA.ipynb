{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext(\"local\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|One of the other ...| positive|\n",
      "|A wonderful littl...| positive|\n",
      "|I thought this wa...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "tFile=\"data\\IMDB Dataset.csv\"\n",
    "df = spark.read.csv(tFile,header=True)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(.3)\n",
    "#df= df.where(F.col(\"sentiment\")==\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "| positive| 7550|\n",
      "| negative| 7425|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"text_h\", F.regexp_replace(F.col(\"text\"), r'<[^>]+>', \"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the special chars. Only lettere will reamin.\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(F.regexp_replace(F.col(\"text_h\"), \"[^a-zA-Z ]\", \"\"),' +',\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+\n",
      "|                text|sentiment|              text_h|              text_c|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|Encouraged by the...| negative|Encouraged by the...|Encouraged by the...|\n",
      "|So im not a big f...| negative|So im not a big f...|So im not a big f...|\n",
      "|The cast played S...| negative|The cast played S...|The cast played S...|\n",
      "|Some films just s...| positive|Some films just s...|Some films just s...|\n",
      "|This movie made i...| negative|This movie made i...|This movie made i...|\n",
      "|What an absolutel...| positive|What an absolutel...|What an absolutel...|\n",
      "|'War movie' is a ...| positive|'War movie' is a ...|War movie is a Ho...|\n",
      "|I watched this fi...| negative|I watched this fi...|I watched this fi...|\n",
      "|I bought this fil...| negative|I bought this fil...|I bought this fil...|\n",
      "|Of all the films ...| negative|Of all the films ...|Of all the films ...|\n",
      "|As a disclaimer, ...| positive|As a disclaimer, ...|As a disclaimer I...|\n",
      "|Average (and surp...| negative|Average (and surp...|Average and surpr...|\n",
      "|As someone has al...| negative|As someone has al...|As someone has al...|\n",
      "|What happened? Wh...| negative|What happened? Wh...|What happened Wha...|\n",
      "|So let's begin!))...| positive|So let's begin!))...|So lets beginThe ...|\n",
      "|An unmarried woma...| negative|An unmarried woma...|An unmarried woma...|\n",
      "|DON'T TORTURE A D...| positive|DON'T TORTURE A D...|DONT TORTURE A DU...|\n",
      "|I'm not sure why ...| negative|I'm not sure why ...|Im not sure why t...|\n",
      "|I thought that Mu...| positive|I thought that Mu...|I thought that Mu...|\n",
      "|I am not a golf f...| positive|I am not a golf f...|I am not a golf f...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer,IDF\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LDA model wiht two topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessin pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "#countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features\", vocabSize=500)\n",
    "#countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features\", vocabSize=500,minDF=10, maxDF=1000)\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000)\n",
    "\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, countVectorizer,idf])\n",
    "data_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'film', 'one', 'like', 'good', 'even', 'time', 'really', 'see', 'story', 'much', 'well', 'get', 'bad', 'great', 'also', 'people', 'first', 'dont', 'movies', 'made', 'films', 'make', 'way', 'characters', 'think', 'seen', 'watch', 'character', 'never', 'two', 'many', 'love', 'show', 'plot', 'little', 'best', 'acting', 'know', 'ever', 'life', 'better', 'scene', 'man', 'say', 'scenes', 'still', 'end', 'something', 'go', 'real', 'back', 'actors', 'im', 'watching', 'thing', 'didnt', 'doesnt', 'though', 'years', 'actually', 'makes', 'funny', 'nothing', 'look', 'another', 'find', 'lot', 'going', 'work', 'old', 'every', 'cant', 'new', 'part', 'us', 'director', 'pretty', 'quite', 'thats', 'want', 'around', 'take', 'cast', 'seems', 'fact', 'got', 'things', 'big', 'young', 'thought', 'give', 'enough', 'isnt', 'world', 'may', 'music', 'horror', 'long', 'interesting']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = data_model.stages[2].vocabulary\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|sentiment|              text_h|              text_c|               words|            filtered|          features_c|            features|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Encouraged by the...| negative|Encouraged by the...|Encouraged by the...|[encouraged, by, ...|[encouraged, posi...|(1000,[1,2,8,13,2...|(1000,[1,2,8,13,2...|\n",
      "|So im not a big f...| negative|So im not a big f...|So im not a big f...|[so, im, not, a, ...|[im, big, fan, bo...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|The cast played S...| negative|The cast played S...|The cast played S...|[the, cast, playe...|[cast, played, sh...|(1000,[0,29,38,44...|(1000,[0,29,38,44...|\n",
      "|Some films just s...| positive|Some films just s...|Some films just s...|[some, films, jus...|[films, simply, r...|(1000,[1,2,9,10,1...|(1000,[1,2,9,10,1...|\n",
      "|This movie made i...| negative|This movie made i...|This movie made i...|[this, movie, mad...|[movie, made, one...|(1000,[0,2,3,6,9,...|(1000,[0,2,3,6,9,...|\n",
      "|What an absolutel...| positive|What an absolutel...|What an absolutel...|[what, an, absolu...|[absolutely, stun...|(1000,[0,6,7,10,2...|(1000,[0,6,7,10,2...|\n",
      "|'War movie' is a ...| positive|'War movie' is a ...|War movie is a Ho...|[war, movie, is, ...|[war, movie, holl...|(1000,[0,1,5,9,10...|(1000,[0,1,5,9,10...|\n",
      "|I watched this fi...| negative|I watched this fi...|I watched this fi...|[i, watched, this...|[watched, film, r...|(1000,[0,1,3,5,7,...|(1000,[0,1,3,5,7,...|\n",
      "|I bought this fil...| negative|I bought this fil...|I bought this fil...|[i, bought, this,...|[bought, film, bl...|(1000,[0,1,2,3,5,...|(1000,[0,1,2,3,5,...|\n",
      "|Of all the films ...| negative|Of all the films ...|Of all the films ...|[of, all, the, fi...|[films, seen, one...|(1000,[0,2,3,19,2...|(1000,[0,2,3,19,2...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = data_model.transform(df)\n",
    "dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find two topics\n",
    "lda = LDA(k=2, maxIter=20)\n",
    "model = lda.fit(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(1000, 2, [1867.8688, 2861.3647, 1780.3746, 1278.9474, 1376.8069, 1131.986, 1406.4946, 1193.581, ..., 313.8083, 382.3281, 226.4952, 24.3532, 309.7665, 240.8443, 93.8796, 590.9369], 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the LDA transformation matrix\n",
    "model.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices      |termWeights                                                                                                    |\n",
      "+-----+-----------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[1, 9, 14, 40, 0]|[0.0059993706591617785, 0.00421333168389642, 0.004075364779163437, 0.003961109057541186, 0.0039163260799191905]|\n",
      "|1    |[0, 1, 13, 3, 7] |[0.006357085823521961, 0.005371918531223365, 0.005195876911487453, 0.004647565655955355, 0.0041393613297162225]|\n",
      "+-----+-----------------+---------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics\n",
    "topics = model.describeTopics(5)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'story', 'great', 'life', 'movie', 'also', 'one', 'love', 'best', 'two', 'man', 'show', 'characters', 'well', 'young']\n",
      "['movie', 'film', 'bad', 'like', 'really', 'even', 'good', 'dont', 'get', 'one', 'movies', 'see', 'plot', 'people', 'say']\n"
     ]
    }
   ],
   "source": [
    "# Print most important words per topic\n",
    "topics = model.describeTopics(15)\n",
    "for r in topics.select(\"termIndices\").collect():\n",
    "    rez = []\n",
    "    for l in r:\n",
    "        for i in l:\n",
    "            rez.append(vocabulary[i])\n",
    "    print(rez[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LDA model wiht ten topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessin pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "#countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=500)\n",
    "# Run 1: Use all the words\n",
    "# countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000)\n",
    "# Run 2: Discard the very frequent words\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000,minDF=10, maxDF=1000)\n",
    "\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, countVectorizer,idf])\n",
    "data_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'version', 'american', 'shot', 'john', 'audience', 'read', 'night', 'war', 'completely', 'death', 'high', 'youre', 'nice', 'fan', 'poor', 'house', 'year', 'simply', 'along', 'use', 'short', 'less', 'friends', 'kids', 'black', 'second', 'used', 'either', 'given', 'men', 'home', 'line', 'stupid', 'half', 'mind', 'dead', 'need', 'rest', 'classic', 'help', 'enjoy', 'father', 'wife', 'wrong', 'star', 'truly', 'try', 'start', 'production', 'couple', 'understand', 'sex', 'recommend', 'boring', 'terrible', 'next', 'performances', 'wonderful', 'moments', 'keep', 'women', 'remember', 'getting', 'mean', 'small', 'video', 'full', 'couldnt', 'budget', 'others', 'gives', 'tell', 'camera', 'human', 'school', 'playing', 'awful', 'let', 'often', 'came', 'guys', 'hollywood', 'name', 'definitely', 'absolutely', 'early', 'lines', 'head', 'liked', 'case', 'perfect', 'episode', 'certainly', 'dialogue', 'top', 'piece', 'perhaps', 'stars', 'sound']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = data_model.stages[2].vocabulary\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|sentiment|              text_h|              text_c|               words|            filtered|          features_c|            features|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Encouraged by the...| negative|Encouraged by the...|Encouraged by the...|[encouraged, by, ...|[encouraged, posi...|(1000,[22,46,54,7...|(1000,[22,46,54,7...|\n",
      "|So im not a big f...| negative|So im not a big f...|So im not a big f...|[so, im, not, a, ...|[im, big, fan, bo...|(1000,[13,14,19,2...|(1000,[13,14,19,2...|\n",
      "|The cast played S...| negative|The cast played S...|The cast played S...|[the, cast, playe...|[cast, played, sh...|(1000,[60,87,180,...|(1000,[60,87,180,...|\n",
      "|Some films just s...| positive|Some films just s...|Some films just s...|[some, films, jus...|[films, simply, r...|(1000,[1,18,41,10...|(1000,[1,18,41,10...|\n",
      "|This movie made i...| negative|This movie made i...|This movie made i...|[this, movie, mad...|[movie, made, one...|(1000,[28,32,45,7...|(1000,[28,32,45,7...|\n",
      "|What an absolutel...| positive|What an absolutel...|What an absolutel...|[what, an, absolu...|[absolutely, stun...|(1000,[48,85,89,1...|(1000,[48,85,89,1...|\n",
      "|'War movie' is a ...| positive|'War movie' is a ...|War movie is a Ho...|[war, movie, is, ...|[war, movie, holl...|(1000,[5,8,19,20,...|(1000,[5,8,19,20,...|\n",
      "|I watched this fi...| negative|I watched this fi...|I watched this fi...|[i, watched, this...|[watched, film, r...|(1000,[13,34,45,5...|(1000,[13,34,45,5...|\n",
      "|I bought this fil...| negative|I bought this fil...|I bought this fil...|[i, bought, this,...|[bought, film, bl...|(1000,[1,10,34,78...|(1000,[1,10,34,78...|\n",
      "|Of all the films ...| negative|Of all the films ...|Of all the films ...|[of, all, the, fi...|[films, seen, one...|(1000,[16,46,126,...|(1000,[16,46,126,...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = data_model.transform(df)\n",
    "dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find two topics\n",
    "lda = LDA(k=10, maxIter=20)\n",
    "model = lda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-------------------------+----------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices              |termWeights                                                                                                     |\n",
      "+-----+-------------------------+----------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[167, 219, 867, 916, 31] |[0.008098707900609042, 0.007473186794659393, 0.0060857619621374846, 0.005692707050313683, 0.0055632589865849645]|\n",
      "|1    |[360, 517, 744, 1, 796]  |[0.008742877521683198, 0.007603318446062859, 0.007182775413896774, 0.007102547163107844, 0.0065358513794967375] |\n",
      "|2    |[92, 383, 344, 446, 8]   |[0.011672105610638785, 0.009681715486126403, 0.007810046644431173, 0.006987408293900571, 0.006207827393365973]  |\n",
      "|3    |[614, 69, 535, 300, 473] |[0.006308397469852298, 0.006297753895197669, 0.005523840121309874, 0.0052255323335133165, 0.004979040781673299] |\n",
      "|4    |[0, 643, 547, 42, 6]     |[0.015235023946754479, 0.008627670519207953, 0.008398814892675925, 0.008259019413892836, 0.007376984216911478]  |\n",
      "|5    |[280, 737, 468, 843, 5]  |[0.008872932562775888, 0.008024472096653495, 0.0065900987516118005, 0.006393466950409825, 0.005576514161780554] |\n",
      "|6    |[8, 764, 152, 448, 410]  |[0.007256965907953513, 0.007138077341141631, 0.007133783525742167, 0.006370540629743969, 0.006210546162119733]  |\n",
      "|7    |[75, 123, 55, 77, 33]    |[0.008320218394917322, 0.0072640507439742635, 0.00705713744728461, 0.0058128702905299034, 0.0056782225670470535]|\n",
      "|8    |[589, 221, 16, 696, 237] |[0.006326835338993676, 0.005225373036439146, 0.005103367774958076, 0.005033561847431727, 0.004782983569877069]  |\n",
      "|9    |[617, 669, 687, 506, 477]|[0.010314136620982737, 0.009557802147238198, 0.008098416919044117, 0.00807649228098762, 0.00743717230566759]    |\n",
      "+-----+-------------------------+----------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics\n",
    "topics = model.describeTopics(5)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['killer', 'police', 'cat', 'slasher', 'home', 'die', 'tries', 'kids', 'murder', 'ill']\n",
      "['musical', 'dance', 'alien', 'version', 'dancing', 'song', 'number', 'remake', 'mean', 'sound']\n",
      "['episode', 'episodes', 'documentary', 'realistic', 'war', 'cinema', 'air', 'dull', 'youll', 'political']\n",
      "['match', 'budget', 'scifi', 'power', 'season', 'science', 'disturbing', 'master', 'sex', 'low']\n",
      "['book', 'joe', 'island', 'father', 'read', 'game', 'baby', 'wonderful', 'relationship', 'brother']\n",
      "['jokes', 'jane', 'jack', 'band', 'audience', 'easy', 'sexual', 'sam', 'given', 'train']\n",
      "['war', 'christmas', 'history', 'subject', 'message', 'understand', 'battle', 'chris', 'certain', 'nature']\n",
      "['school', 'waste', 'terrible', 'awful', 'stupid', 'pathetic', 'monster', 'game', 'couldnt', 'bunch']\n",
      "['de', 'art', 'house', 'la', 'told', 'tom', 'english', 'american', 'water', 'simply']\n",
      "['lee', 'disney', 'creepy', 'peter', 'dr', 'computer', 'star', 'eye', 'songs', 'race']\n"
     ]
    }
   ],
   "source": [
    "# Print most important words per topic\n",
    "topics = model.describeTopics(10)\n",
    "for r in topics.select(\"termIndices\").collect():\n",
    "    rez = []\n",
    "    for l in r:\n",
    "        for i in l:\n",
    "            rez.append(vocabulary[i])\n",
    "    print(rez[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              text_c|   topicDistribution|\n",
      "+--------------------+--------------------+\n",
      "|Encouraged by the...|[0.00134266902034...|\n",
      "|So im not a big f...|[6.04925096092124...|\n",
      "|The cast played S...|[0.00176946977597...|\n",
      "|Some films just s...|[0.00231624133659...|\n",
      "|This movie made i...|[0.32533048337194...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the result\n",
    "transformed = model.transform(dataset)\n",
    "transformed.select(\"text_c\",\"topicDistribution\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf\n",
    "def vect_argmax(row):\n",
    "    row_arr = row.toArray()\n",
    "    max_pos = np.argmax(row_arr)\n",
    "    return(int(max_pos))\n",
    "transformed1 = transformed.withColumn(\"argmax\",vect_argmax(F.col('topicDistribution')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|text_c                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |argmax|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|Encouraged by the positive comments about this film on here I was looking forward to watching this film Bad mistake Ive seen films and this is truly one of the worst of them its awful in almost every way editing pacing storyline acting soundtrack the films only song a lame country tune is played no less than four times The film looks cheap and nasty and is boring in the extreme Rarely have I been so happy to see the end credits of a film The only thing that prevents me giving this a score is Harvey Keitel while this is far from his best performance he at least seems to be making a bit of an effort One for Keitel obsessives only                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |3     |\n",
      "|So im not a big fan of Bolls work but then again not many are I enjoyed his movie Postal maybe im the only one Boll apparently bought the rights to use Far Cry long ago even before the game itself was even finsished People who have enjoyed killing mercs and infiltrating secret research labs located on a tropical island should be warned that this is not Far Cry This is something Mr Boll have schemed together along with his legion of schmucks Feeling loneley on the set Mr Boll invites three of his countrymen to play with These players go by the names of Til Schweiger Udo Kier and Ralf MoellerThree names that actually have made them selfs pretty big in the movie biz So the tale goes like this Jack Carver played by Til Schweiger yes Carver is German all hail the bratwurst eating dudes However I find that Tils acting in this movie is pretty badass People have complained about how hes not really staying true to the whole Carver agenda but we only saw carver in a first person perspective so we dont really know what he looked like when he was kicking a However the storyline in this film is beyond demented We see the evil mad scientist Dr Krieger played by Udo Kier making GeneticallyMutatedsoldiers or GMS as they are called Performing his topsecret research on an island that reminds me of SPOILER Vancouver for some reason Thats right no palm trees here Instead we got some nice rich lumberjackwoods We havent even gone FAR before I started to CRY mehehe I cannot go on any more If you wanna stay true to Bolls shenanigans then go and see this movie you will not be disappointed it delivers the true Boll experience meaning most of it will suckThere are some things worth mentioning that would imply that Boll did a good work on some areas of the film such as some nice boat and fighting scenes Until the whole cromedalbino GMS squad enters the scene and everything just makes me laugh The movie Far Cry reeks of scheisse thats poop for you simpletons from a far if you wanna take a wiff go ahead BTW Carver gets a very annoying sidekick who makes you wanna shoot him the first three minutes hes on screen|7     |\n",
      "|The cast played ShakespeareShakespeare lostI appreciate that this is trying to bring Shakespeare to the masses but why ruin something so goodIs it because The Scottish Play is my favorite Shakespeare I do not know What I do know is that a certain Rev Bowdler hence bowdlerization tried to do something similar in the Victorian eraIn other words you cannot improve perfectionI have no more to write but as I have to write at least ten lines of text and English composition was never my forte I will just have to keep going and say that this movie as the saying goes just does not cut it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |6     |\n",
      "|Some films just simply should not be remade This is one of them In and of itself it is not a bad film But it fails to capture the flavor and the terror of the film of the same title Liam Neeson was excellent as he always is and most of the cast holds up with the exception of Owen Wilson who just did not bring the right feel to the character of Luke But the major fault with this version is that it strayed too far from the Shirley Jackson story in its attempts to be grandiose and lost some of the thrill of the earlier film in a trade off for snazzier special effects Again I will say that in and of itself it is not a bad film But you will enjoy the friction of terror in the older version much more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |4     |\n",
      "|This movie made it into one of my top most awful movies Horrible There wasnt a continuous minute where there wasnt a fight with one monster or another There was no chance for any character development they were too busy running from one sword fight to another I had no emotional attachment except to the big bad machine that wanted to destroy them Scenes were blatantly stolen from other movies LOTR Star Wars and Matrix ExamplesThe ghost scene at the end was stolen from the final scene of the old Star Wars with Yoda Obee One and Vader The spider machine in the beginning was exactly like Frodo being attacked by the spider in Return of the Kings Elijah Wood is the victim in both films and waitit hypnotizes stings its victim and wraps them upuh helloAnd the whole machine vs humans theme WAS the Matrixor TerminatorThere are more examples but why waste the time And will someone tell me what was with the Nazis Nazis There was a juvenile story line rushed to a juvenile conclusion The movie could not decide if it was a childrens movie or an adult movie and wasnt much of either Just awful A real disappointment to say the least Save your money                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |7     |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed1.select(\"text_c\",\"argmax\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('spark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a438fe5e673439fc02ff5cd8cbdc8c17eb0482df38f5adb73093864426e0f81e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
